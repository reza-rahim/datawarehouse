---
- name: modify /etc/fuse.conf
  lineinfile:
     dest: /etc/fuse.conf
     line: user_allow_other


- name: Create {{ fuse_home }}
  file:
    path: '{{ fuse_home }}'
    state: directory
    owner: '{{ fuse_user }}'
    group: '{{ fuse_group }}'


- name: check for '{{ spark_s3_application_dir }}'
  stat:
     path: '{{ spark_s3_application_dir }}'
  register: spark_dir_stat_result

- name: Create {{ spark_s3_application_dir }}
  file:
    path: '{{ spark_s3_application_dir }}'
    state: directory
    owner: '{{ fuse_user }}'
    group: '{{ fuse_group }}'
    mode: 0775
  when: not spark_dir_stat_result.stat.exists

- name: check for '{{ jupyterhub_notebook_dir }}'
  stat:
     path: '{{ jupyterhub_notebook_dir }}'
  register: jupyterhub_notebook_dir_stat_result

- name: create {{ jupyterhub_notebook_dir }}
  file:
     path: '{{ jupyterhub_notebook_dir }}'
     state: directory
     owner: '{{ fuse_user }}'
     group: '{{ fuse_group }}'
     mode: 0775
  when: not jupyterhub_notebook_dir_stat_result.stat.exists

- name: Check that the airlfow dag home exists
  stat:
      path: '{{ airflow_dag_dir }}'
  register: dag_stat_result

- name: create airflow dag directory
  file:
     path: '{{ airflow_dag_dir }}'
     state: directory
     owner: '{{ fuse_user }}'
     group: '{{ fuse_group }}'
     mode: 0775
  when: not dag_stat_result.stat.exists

     
- name: copy fuse scripts  
  template: src='{{ item.src }}' dest='{{ item.dest }}' group='{{ application_group }}' mode=0750
  loop:
     - { src: 'airflow_fuse.sh.j2', dest: '{{ fuse_home }}/airflow_fuse.sh'  }
     - { src: 'jupyterhub_fuse.sh.j2', dest: '{{ fuse_home }}/jupyterhub_fuse.sh'  }
     - { src: 'spark_fuse.sh.j2', dest: '{{ fuse_home }}/spark_fuse.sh'  }
     - { src: 'spark_fuse.sh.j2', dest: '{{ fuse_home }}/spark_fuse.sh'  }
