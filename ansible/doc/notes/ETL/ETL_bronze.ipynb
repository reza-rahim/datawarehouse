{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b2b05e4-1ff7-41b5-94d8-6ba8cc3f96df",
   "metadata": {},
   "source": [
    "### Create the spark context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87fbee65-e367-48fc-a537-3456a1216e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "import os\n",
    "\n",
    "secret = os.environ.get(\"SPARK_AUTH_SECRET\")\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.authenticate\", \"true\")\n",
    "conf.set(\"spark.driver.extraJavaOptions\", f\"-Dspark.authenticate.secret={secret}\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf)\\\n",
    "    .master(\"spark://node1.dw.felicity.net.bd:7077,node2.dw.felicity.net.bd:7077\")\\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ef688-8419-487b-b486-9d50380afe1f",
   "metadata": {},
   "source": [
    "### Creating tmp view for landing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3428ce-0b2b-4a69-968b-8bac8bcce17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### geo_location_csv\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW geo_location_csv(\n",
    "    location_id BIGINT, \n",
    "    country STRING, \n",
    "    state STRING, \n",
    "    city STRING, \n",
    "    postal_code STRING\n",
    ")\n",
    "USING csv\n",
    "OPTIONS (\n",
    "  path 's3a://spark-data/landing/geo_location.csv',\n",
    "  header 'true'\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "### customer_csv\n",
    "spark.sql(f\"\"\" \n",
    "CREATE OR REPLACE TEMPORARY VIEW customer_csv (\n",
    "    customer_id INT,\n",
    "    full_name STRING,\n",
    "    email STRING,\n",
    "    phone_number STRING,\n",
    "    location_id INT,\n",
    "    created_at TIMESTAMP\n",
    ")\n",
    "USING csv\n",
    "OPTIONS (\n",
    "  path 's3a://spark-data/landing/customer.csv',\n",
    "  header 'true'\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "### product_csv\n",
    "spark.sql(f\"\"\" \n",
    "CREATE OR REPLACE TEMPORARY VIEW product_csv (\n",
    "    product_id INT,\n",
    "    product_name STRING,\n",
    "    description STRING,\n",
    "    category STRING,\n",
    "    price DECIMAL(10,2),\n",
    "    in_stock BOOLEAN,\n",
    "    created_at TIMESTAMP\n",
    ")\n",
    "USING csv\n",
    "OPTIONS (\n",
    "  path 's3a://spark-data/landing/product.csv',\n",
    "  header 'true'\n",
    ");\n",
    "\"\"\");\n",
    "\n",
    "### sales_order_csv\n",
    "spark.sql(f\"\"\" \n",
    "CREATE OR REPLACE TEMPORARY VIEW sales_order_csv (\n",
    "    order_id INT,\n",
    "    customer_id INT,\n",
    "    order_date TIMESTAMP,\n",
    "    total_amount DECIMAL(12,2),\n",
    "    status STRING,\n",
    "    updated_at TIMESTAMP\n",
    ")\n",
    "USING csv\n",
    "OPTIONS (\n",
    "  path 's3a://spark-data/landing/sales_order.csv',\n",
    "  header 'true'\n",
    ");\n",
    "\"\"\");\n",
    "\n",
    "### order_item_csv\n",
    "spark.sql(f\"\"\" \n",
    "CREATE OR REPLACE TEMPORARY VIEW order_item_csv (\n",
    "    order_item_id INT,\n",
    "    order_id INT,\n",
    "    product_id INT,\n",
    "    quantity INT,\n",
    "    unit_price DECIMAL(10,2),\n",
    "    total_price DECIMAL(12,2)\n",
    ")\n",
    "USING csv\n",
    "OPTIONS (\n",
    "  path 's3a://spark-data/landing/order_item.csv',\n",
    "  header 'true'\n",
    ");\n",
    "\"\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4cc6c0-681f-4ddc-bd18-484d05a22782",
   "metadata": {},
   "source": [
    "### Merging landing data into bronze layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a9b713f5-8956-4cf0-9698-698d68706f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 17:16:12 WARN HiveConf: HiveConf of name hive.metastore.ssl.need.client.auth does not exist\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "MERGE INTO bronze.geo_location AS target\n",
    "USING (\n",
    "  SELECT *, current_timestamp() AS load_timestamp\n",
    "  FROM geo_location_csv\n",
    ") AS source\n",
    "ON target.location_id = source.location_id\n",
    "\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    target.country = source.country,\n",
    "    target.state = source.state,\n",
    "    target.city = source.city,\n",
    "    target.postal_code = source.postal_code,\n",
    "    target.load_timestamp = source.load_timestamp\n",
    "\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT (location_id, country, state, city, postal_code, load_timestamp)\n",
    "  VALUES (source.location_id, source.country, source.state, source.city, source.postal_code, source.load_timestamp);\n",
    "\"\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7bee0fd3-84b4-4336-8082-a1ab99bb50ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      15|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select count(*) from  bronze.geo_location; \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5b2f6be1-5589-4951-bcb1-2618819212c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "MERGE INTO bronze.customer AS target\n",
    "USING (\n",
    "  SELECT *, current_timestamp() AS load_timestamp\n",
    "  FROM customer_csv\n",
    ") AS source\n",
    "ON target.customer_id = source.customer_id\n",
    "\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    full_name     = source.full_name,\n",
    "    email         = source.email,\n",
    "    phone_number  = source.phone_number,\n",
    "    location_id   = source.location_id,\n",
    "    created_at    = source.created_at,\n",
    "    load_timestamp = source.load_timestamp\n",
    "\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT (\n",
    "    customer_id, full_name, email, phone_number, location_id, created_at, load_timestamp\n",
    "  )\n",
    "  VALUES (\n",
    "    source.customer_id, source.full_name, source.email, source.phone_number,\n",
    "    source.location_id, source.created_at, source.load_timestamp\n",
    "  );\n",
    "\n",
    "\"\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "576d4d26-5829-4ce3-8cbb-9edcb0b0d430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     250|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select count(*) from  bronze.customer; \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f1e699be-0be1-47d3-8cf0-41826f140fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "MERGE INTO bronze.product AS target\n",
    "USING (\n",
    "  SELECT *, current_timestamp() AS load_timestamp\n",
    "  FROM product_csv\n",
    ") AS source\n",
    "ON target.product_id = source.product_id\n",
    "\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    product_name   = source.product_name,\n",
    "    description    = source.description,\n",
    "    category       = source.category,\n",
    "    price          = source.price,\n",
    "    in_stock       = source.in_stock,\n",
    "    created_at     = source.created_at,\n",
    "    load_timestamp = source.load_timestamp\n",
    "\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT (\n",
    "    product_id, product_name, description, category, price,\n",
    "    in_stock, created_at, load_timestamp\n",
    "  )\n",
    "  VALUES (\n",
    "    source.product_id, source.product_name, source.description, source.category,\n",
    "    source.price, source.in_stock, source.created_at, source.load_timestamp\n",
    "  );\n",
    "\n",
    "\"\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d7a82360-f503-46b9-919d-963fea36ff13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      25|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select count(*) from  bronze.product; \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a696c8a1-e28c-440a-9df9-d78d6eaf6570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 17:35:50 WARN HiveConf: HiveConf of name hive.metastore.ssl.need.client.auth does not exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "MERGE INTO bronze.sales_order AS target\n",
    "USING (\n",
    "  SELECT \n",
    "    order_id,\n",
    "    customer_id,\n",
    "    order_date,\n",
    "    total_amount,\n",
    "    status,\n",
    "    current_timestamp() AS updated_at,\n",
    "    current_timestamp() AS load_timestamp\n",
    "  FROM sales_order_csv\n",
    ") AS source\n",
    "ON target.order_id = source.order_id\n",
    "\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    customer_id    = source.customer_id,\n",
    "    order_date     = source.order_date,\n",
    "    total_amount   = source.total_amount,\n",
    "    status         = source.status,\n",
    "    updated_at     = source.updated_at,\n",
    "    load_timestamp = source.load_timestamp\n",
    "\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT (\n",
    "    order_id, customer_id, order_date, total_amount, status,\n",
    "    updated_at, load_timestamp\n",
    "  )\n",
    "  VALUES (\n",
    "    source.order_id, source.customer_id, source.order_date,\n",
    "    source.total_amount, source.status, source.updated_at, source.load_timestamp\n",
    "  );\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "653091ad-756c-4ca4-b4d1-86cd31b3a455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    1000|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select count(*) from  bronze.sales_order; \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a5221198-cd1f-48d7-9873-4dc521950e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "MERGE INTO bronze.order_item AS target\n",
    "USING (\n",
    "  SELECT \n",
    "    order_item_id,\n",
    "    order_id,\n",
    "    product_id,\n",
    "    quantity,\n",
    "    unit_price,\n",
    "    total_price,\n",
    "    current_timestamp() AS load_timestamp\n",
    "  FROM order_item_csv\n",
    ") AS source\n",
    "ON target.order_item_id = source.order_item_id\n",
    "\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    order_id       = source.order_id,\n",
    "    product_id     = source.product_id,\n",
    "    quantity       = source.quantity,\n",
    "    unit_price     = source.unit_price,\n",
    "    total_price    = source.total_price,\n",
    "    load_timestamp = source.load_timestamp\n",
    "\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT (\n",
    "    order_item_id, order_id, product_id, quantity, unit_price, total_price, load_timestamp\n",
    "  )\n",
    "  VALUES (\n",
    "    source.order_item_id, source.order_id, source.product_id, source.quantity,\n",
    "    source.unit_price, source.total_price, source.load_timestamp\n",
    "  );\n",
    "\n",
    "\"\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4dec5eb7-5d66-4550-8ec9-2081234f1e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 23:53:59 WARN HiveConf: HiveConf of name hive.metastore.ssl.need.client.auth does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    3000|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select count(*) from  bronze.order_item; \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce01993-38a8-486c-8784-322d28cd187f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
